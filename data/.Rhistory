ggplot(data=y, aes(x=days_since_created, y=cdf, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Age of Account (in days)') + ylab('CDF (Percent of Users)') +
ggtitle("CDF of Users Over Time")
head(data)
nrow(data)
ggplot(data=data, aes(x=sign_ups, color=age_group, fill=age_group)) +
geom_histogram(binwidth = 1, aes(y = ..density.. )) +
scale_y_continuous(labels=comma) +
scale_x_continuous(labels=comma, limits=c(0, 15)) +
xlab('Number of Sign-Ups per User') + ylab('Density') +
guides(guide = guide_legend(title = "Age Group" )) +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=data, aes(x=sign_ups, color=black, fill=age_group)) +
geom_histogram(binwidth = 1, aes(y = ..density.. )) +
scale_y_continuous(labels=comma) +
scale_x_continuous(labels=comma, limits=c(0, 15)) +
xlab('Number of Sign-Ups per User') + ylab('Density') +
guides(guide = guide_legend(title = "Age Group" )) +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=data, aes(x=sign_ups, fill=age_group)) +
geom_histogram(binwidth = 1, aes(y = ..density.. )) +
scale_y_continuous(labels=comma) +
scale_x_continuous(labels=comma, limits=c(0, 15)) +
xlab('Number of Sign-Ups per User') + ylab('Density') +
guides(guide = guide_legend(title = "Age Group" )) +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
# Summarize the data
age_data <- data %>%
group_by(usr_age) %>%
summarise(num=(n()/nrow(data)*100.), msu=mean(sign_ups))
age_grouped_data <- data %>%
group_by(age_group) %>%
summarise(msu = mean(sign_ups), std=sd(sign_ups))
age_grouped_data
age_data
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group, fill=age_group)) +
geom_bar(stat = "identity") +
scale_x_continuous(labels=comma, limits=c(0, 15)) +
scale_y_continuous(labels=comma) +
xlab('Age of Account (in days)') + ylab('Percent of Users') +
ggtitle("Percent of Users Over Time")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group, fill=age_group)) +
geom_bar(stat = "identity") +
facet_wrap(~ age_group)+
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
xlab('Number of Sign-Ups per User') + ylab('Density') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")+
theme(legend.position="none")
ggplot(data=z, aes(x=sign_ups, y=cdf, color=age_group)) +
geom_line() +
scale_x_continuous(reverse=TRUE, labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=cdf, color=age_group)) +
geom_line() +
scale_x_continuous(reverse=TRUE, labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=cdf, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
a <- z %>%
group_by(age_group) %>%
summarise(num=sum(frac))
a
sign_up_stat1 <-group1 %>%
group_by(sign_ups) %>%
summarize(num=n()) %>%
mutate(frac=num/sum(num)) %>%
arrange(-sign_ups) %>%
mutate(cdf=cumsum(num)/sum(num)) %>%
mutate(tots=sum(num)) %>%
mutate(age_group = rep("22+", length(num)))
sign_up_stat2 <-group2 %>%
group_by(sign_ups) %>%
summarize(num=n()) %>%
mutate(frac=num/sum(num)) %>%
arrange(-sign_ups) %>%
mutate(cdf=cumsum(num)/sum(num)) %>%
mutate(tots=sum(num)) %>%
mutate(age_group = rep("18-21", length(num)))
sign_up_stat3 <-group3 %>%
group_by(sign_ups) %>%
summarize(num=n()) %>%
mutate(frac=num/sum(num)) %>%
arrange(-sign_ups) %>%
mutate(cdf=cumsum(num)/sum(num)) %>%
mutate(tots=sum(num)) %>%
mutate(age_group = rep("below 18", length(num)))
z <- rbind(sign_up_stat1, sign_up_stat2, sign_up_stat3)
ggplot(data=z, aes(x=sign_ups, y=tot, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
head(z)
ggplot(data=z, aes(x=sign_ups, y=tots, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
head(z)
ggplot(data=z, aes(x=sign_ups, y=num, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group, fill=age_group)) +
geom_bar(stat = "identity") +
facet_wrap(~ age_group)+
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
xlab('Number of Sign-Ups per User') + ylab('Density') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")+
theme(legend.position="none")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('CDF') +
ggtitle("Zoom in on the Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:20)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 11), breaks=c(1:20)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, limits=c(0, 20), breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
scale_x_continuous(labels=comma, breaks=c(1:10)) +
scale_x_continuous(labels=comma, breaks=c(1:10)) +
)
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma, breaks=c(1:10)) +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_continuous(labels=comma) +
scale_x_log10() +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
ggplot(data=z, aes(x=sign_ups, y=frac, color=age_group)) +
geom_line() +
scale_x_log10() +
scale_y_continuous(labels=percent) +
guides(colour = guide_legend(title = "Age Group")) +
xlab('Number of Sign-Ups') + ylab('Percent of Users') +
ggtitle("The Number of Sign-Ups per User by Age Group")
ggplot(data=data, aes(x=usr_age)) +
geom_histogram(binwidth = 1, aes(y = ..density..),
color="black", fill = "white") +
scale_x_continuous(breaks=c(13:26), labels=comma) +
scale_y_continuous(breaks=c(1:6)/20, labels=percent) +
xlab('Age of Users (Years)') + ylab('Density (%)') +
ggtitle("Age Breakdown")
ggplot(data=data, aes(x=usr_age)) +
geom_histogram(binwidth = 1, aes(y = ..density..),
color="black", fill = "white") +
scale_x_continuous(breaks=c(13:26), labels=comma) +
scale_y_continuous(breaks=c(1:6)/20, labels=percent) +
xlab('Age of Users (in years)') + ylab('Density (%)') +
ggtitle("Age Breakdown")
ggplot(data=data, aes(x=usr_age)) +
geom_histogram(binwidth = 1, aes(y = ..density..),
color="black", fill = "white") +
scale_x_continuous(breaks=c(13:26), labels=comma) +
scale_y_continuous(breaks=c(1:6)/20, labels=percent) +
xlab('Age of Users (in years)') + ylab('Density') +
ggtitle("Age Breakdown")
ggplot(data=data, aes(x=usr_age)) +
geom_histogram(binwidth = 1, aes(y = ..density..),
color="black", fill = "white") +
scale_x_continuous(breaks=c(13:26), labels=comma, limits=c(13,26)) +
scale_y_continuous(breaks=c(1:6)/20, labels=percent) +
xlab('Age of Users (in years)') + ylab('Density') +
ggtitle("Age Breakdown")
View(time_data_1)
source('~/Desktop/playingwithDoSome.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
p <- 0.3
n <- 100
P.hat <- rep(0,10^5)
for(i in 1:10^5) {
X <- rbinom(n,1,p)
P.hat[i] <- mean(X)
}
head(P.hat)
qplot(x=P.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=p) +
geom_vline(xintercept=mean(P.hat), linetype=2, color="red")
qplot(x=P.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=p) +
geom_vline(xintercept=mean(P.hat), linetype=2, color="red")
library(ggplot2)
library(reshape)
theme_set(theme_bw())
set.seed(42)
p <- 0.3
n <- 100
P.hat <- rep(0,10^5)
for(i in 1:10^5) {
X <- rbinom(n,1,p)
P.hat[i] <- mean(X)
}
# plot the sampling distribution
qplot(x=P.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=p) +
geom_vline(xintercept=mean(P.hat), linetype=2, color="red")
# compute upper and lower confidence intervals
LCL <- P.hat - 1.96*sqrt(P.hat*(1-P.hat)/n)
UCL <- P.hat + 1.96*sqrt(P.hat*(1-P.hat)/n)
# check how often the true proportion is contained in the estimated confidence interval
mean(p >= LCL & p <= UCL)
# plot 100 confidence intervals and the true value
plot_data <- data.frame(P.hat, LCL, UCL)[1:100,]
plot_data <- transform(plot_data, contains_p=(p >= LCL & p <= UCL))
ggplot(data=plot_data, aes(x=1:nrow(plot_data), y=P.hat, color=contains_p)) +
geom_pointrange(aes(ymin=LCL, ymax=UCL)) +
geom_hline(yintercept=p, linetype=2) +
xlab('') +
scale_color_manual(values=c("red","darkgreen")) +
theme(legend.position="none")
LCL <- P.hat - 1.96*sqrt(P.hat*(1-P.hat)/n)
LCL <- P.hat - 1.96*sqrt(P.hat*(1-P.hat)/n)
UCL <- P.hat + 1.96*sqrt(P.hat*(1-P.hat)/n)
mean(p >= LCL & p <= UCL)
# construct a null distribution: what would happen if the coin were fair?
p <- 0.5
n <- 100
P0.hat <- rep(0,10^5)
for(i in 1:10^5) {
X <- rbinom(n,1,p)
P0.hat[i] <- mean(X)
}
# plot the null distribution and see where the observed estimate lies in it
qplot(x=P0.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=P.hat[1], linetype=2, color="red")
# compare this to one of our experiments with the biased coin above
# how likely is it that we would see an estimate this extreme if the coin really were fair?
num.as.extreme <- sum(P0.hat <= P.hat[1])
p.value <- num.as.extreme / length(P.hat)
library(ggplot2)
library(reshape)
theme_set(theme_bw())
set.seed(42)
p <- 0.3
n <- 100
P.hat <- rep(0,10^5)
for(i in 1:10^5) {
X <- rbinom(n,1,p)
P.hat[i] <- mean(X)
}
# plot the sampling distribution
qplot(x=P.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=p) +
geom_vline(xintercept=mean(P.hat), linetype=2, color="red")
# compute upper and lower confidence intervals
LCL <- P.hat - 1.96*sqrt(P.hat*(1-P.hat)/n)
UCL <- P.hat + 1.96*sqrt(P.hat*(1-P.hat)/n)
# check how often the true proportion is contained in the estimated confidence interval
mean(p >= LCL & p <= UCL)
# plot 100 confidence intervals and the true value
plot_data <- data.frame(P.hat, LCL, UCL)[1:100,]
plot_data <- transform(plot_data, contains_p=(p >= LCL & p <= UCL))
ggplot(data=plot_data, aes(x=1:nrow(plot_data), y=P.hat, color=contains_p)) +
geom_pointrange(aes(ymin=LCL, ymax=UCL)) +
geom_hline(yintercept=p, linetype=2) +
xlab('') +
scale_color_manual(values=c("red","darkgreen")) +
theme(legend.position="none")
# construct a null distribution: what would happen if the coin were fair?
p <- 0.5
n <- 100
P0.hat <- rep(0,10^5)
for(i in 1:10^5) {
X <- rbinom(n,1,p)
P0.hat[i] <- mean(X)
}
# plot the null distribution and see where the observed estimate lies in it
qplot(x=P0.hat, geom="histogram", binwidth=0.01) +
geom_vline(xintercept=P.hat[1], linetype=2, color="red")
# compare this to one of our experiments with the biased coin above
# how likely is it that we would see an estimate this extreme if the coin really were fair?
num.as.extreme <- sum(P0.hat <= P.hat[1])
p.value <- num.as.extreme / length(P.hat)
p.value
install.packages("GGally")
library(GGally)
ggpairs(iris, colour='Species', alpha=0.4)
library(GGally)
setwd("~/Documents/Repository/edavproj/data/")
require(dplyr)
#==========get directory of high schools and SAT results =============
hs <- read.csv("DOE_High_School_Directory.csv", header=T, stringsAsFactors = F)
hs <- select(hs, -boro, -se_services, -ell_programs,  -school_accessibility_description, -number_programs)
hs$lonlat <- tail(strsplit(hs$Location, '\n')[[1]], n=1)
countClasses <- function(x) {
xs <- strsplit(x, ",", fixed=TRUE)
l = length(xs[[1]])
return(l)
}
hs$advancedplacement_courses <- sapply(hs$advancedplacement_courses, countClasses)
hs$online_ap_courses <- sapply(hs$online_ap_courses, countClasses)
hs$total_students = as.numeric(hs$total_students)
sat <- read.csv("SAT_Results_2012.csv", header=T, stringsAsFactors = F)
names(sat) <- tolower(names(sat))
sat <- select(sat, -school.name)
colnames(sat) <- c('dbn', 'num_taker', 'critical_avg', 'math_avg', 'writing_avg')
sat$num_taker = as.numeric(sat$num_taker)
sat$critical_avg = as.numeric(sat$critical_avg)
sat$math_avg = as.numeric(sat$math_avg)
sat$writing_avg = as.numeric(sat$writing_avg)
sat <- na.omit(sat)
#========= get safety report ================
safety <- read.csv("School_Safety_Report.csv", header=T, stringsAsFactors = F)
names(safety) <- tolower(names(safety))
safety <- select(safety, -address, -location.name, -location.code, -borough, -building.name, -engroupa, -schools.in.building, -building.code, -id, -register, -rangea)
# according to http://schools.nyc.gov/OurSchools/SchoolSafetyReport.htm: N/A means 0 crime
safety[safety == 'N/A'] <- 0
safety_wodbn <- select(safety, -dbn)
safety_wodbn <- sapply(safety_wodbn, as.numeric)
safety_wodbn <- data.frame(safety_wodbn)
safety <- cbind(safety$dbn, safety_wodbn)
colnames(safety)[1] = 'dbn'
#========= get class size clean data =============
class_size <- read.csv("2010-2011_Class_Size_School-level_detail.csv", header=T, stringsAsFactors = F)
# construct dbn from CSD and schoolcode
csd1 = subset(class_size, CSD<10)
csd2 = subset(class_size, CSD>=10)
csd1$dbn = paste0('0', csd1$CSD, csd1$SCHOOL.CODE)
csd2$dbn = paste0(csd2$CSD, csd2$SCHOOL.CODE)
class_size = rbind(csd1, csd2)
class_size <- select(class_size, dbn, GRADE, NUMBER.OF.STUDENTS...SEATS.FILLED, NUMBER.OF.SECTIONS, AVERAGE.CLASS.SIZE, SIZE.OF.SMALLEST.CLASS, SIZE.OF.LARGEST.CLASS)
colnames(class_size) <- c('dbn', 'grade', 'num_stu', 'num_class', 'avg_size', 'smallest_size', 'largest_size')
require(sqldf)
class = sqldf("SELECT dbn, sum(num_stu),sum(num_class) FROM class_size WHERE grade='09-12' GROUP BY dbn")
colnames(class) <- c('dbn', 'total_stu', 'total_class')
class$avg_size = class$total_stu / class$total_class
#========== get gender ratio clean data ===========
gender <- read.csv("Graduation_Outcomes_School_Level_Classes_of_2005-2011_Gender.csv", header=T, stringsAsFactors = F)
gender = subset(gender, Cohort.Year==2007 & Cohort.Category=='4 Year August')
names(gender) <- tolower(names(gender))
gender <- select(gender, dbn, demographic, total.cohort.num)
female <- subset(gender, demographic=='Female')
male <- subset(gender, demographic=='Male')
female <- select(female, dbn, total.cohort.num)
male <- select(male, dbn, total.cohort.num)
names(female) = c('dbn', 'female')
names(male) = c('dbn', 'male')
gender <- merge(female, male, by = "dbn", all = TRUE)
gender[is.na(gender)] <- 0
gender$p_male = gender$male / (gender$male + gender$female)
#=========== get income data =============
income <- read.csv("zipcode_income.csv", header=T, stringsAsFactors = F)
colnames(income) = c('zip', 'zip_lonlat', 'zip_pop', 'avg_household')
income$avg_household = gsub('\\$','',income$avg_household)
income$avg_household = gsub(',','',income$avg_household)
income$avg_household = as.numeric(income$avg_household)
#=========== join tables ============
hsSAT <- inner_join(sat, hs, by="dbn")
all <- left_join(hsSAT, safety, by='dbn')
all <- left_join(all, class, by='dbn')
all <- left_join(all, gender, by='dbn')
all <- left_join(all, income, by='zip')
#=========== correlation models ============
normalize <- function(x) {
mean = mean(x[is.na(x)==FALSE])
sd = sd(x[is.na(x)==FALSE])
normalized_x = (x-mean)/sd
return(normalized_x)
}
all$critical_norm <- normalize(all$critical_avg)
all$math_norm <- normalize(all$math_avg)
all$writing_norm <- normalize(all$writing_avg)
all$avg_household_norm <- normalize(all$avg_household)
all$p_male_norm <- normalize(all$p_male)
all$avg_size_norm <- normalize(all$avg_size)
all$avgofmajor.n_norm <- normalize(all$avgofmajor.n)
all$avgofvio.n_norm <- normalize(all$avgofvio.n)
ggpairs(all, alpha=0.4)
head(all)
setwd("~/github/edavproj/data")
library(GGally)
setwd("~/Documents/Repository/edavproj/data/")
require(dplyr)
#==========get directory of high schools and SAT results =============
hs <- read.csv("DOE_High_School_Directory.csv", header=T, stringsAsFactors = F)
hs <- select(hs, -boro, -se_services, -ell_programs,  -school_accessibility_description, -number_programs)
hs$lonlat <- tail(strsplit(hs$Location, '\n')[[1]], n=1)
countClasses <- function(x) {
xs <- strsplit(x, ",", fixed=TRUE)
l = length(xs[[1]])
return(l)
}
hs$advancedplacement_courses <- sapply(hs$advancedplacement_courses, countClasses)
hs$online_ap_courses <- sapply(hs$online_ap_courses, countClasses)
hs$total_students = as.numeric(hs$total_students)
sat <- read.csv("SAT_Results_2012.csv", header=T, stringsAsFactors = F)
names(sat) <- tolower(names(sat))
sat <- select(sat, -school.name)
colnames(sat) <- c('dbn', 'num_taker', 'critical_avg', 'math_avg', 'writing_avg')
sat$num_taker = as.numeric(sat$num_taker)
sat$critical_avg = as.numeric(sat$critical_avg)
sat$math_avg = as.numeric(sat$math_avg)
sat$writing_avg = as.numeric(sat$writing_avg)
sat <- na.omit(sat)
#========= get safety report ================
safety <- read.csv("School_Safety_Report.csv", header=T, stringsAsFactors = F)
names(safety) <- tolower(names(safety))
safety <- select(safety, -address, -location.name, -location.code, -borough, -building.name, -engroupa, -schools.in.building, -building.code, -id, -register, -rangea)
# according to http://schools.nyc.gov/OurSchools/SchoolSafetyReport.htm: N/A means 0 crime
safety[safety == 'N/A'] <- 0
safety_wodbn <- select(safety, -dbn)
safety_wodbn <- sapply(safety_wodbn, as.numeric)
safety_wodbn <- data.frame(safety_wodbn)
safety <- cbind(safety$dbn, safety_wodbn)
colnames(safety)[1] = 'dbn'
#========= get class size clean data =============
class_size <- read.csv("2010-2011_Class_Size_School-level_detail.csv", header=T, stringsAsFactors = F)
# construct dbn from CSD and schoolcode
csd1 = subset(class_size, CSD<10)
csd2 = subset(class_size, CSD>=10)
csd1$dbn = paste0('0', csd1$CSD, csd1$SCHOOL.CODE)
csd2$dbn = paste0(csd2$CSD, csd2$SCHOOL.CODE)
class_size = rbind(csd1, csd2)
class_size <- select(class_size, dbn, GRADE, NUMBER.OF.STUDENTS...SEATS.FILLED, NUMBER.OF.SECTIONS, AVERAGE.CLASS.SIZE, SIZE.OF.SMALLEST.CLASS, SIZE.OF.LARGEST.CLASS)
colnames(class_size) <- c('dbn', 'grade', 'num_stu', 'num_class', 'avg_size', 'smallest_size', 'largest_size')
require(sqldf)
class = sqldf("SELECT dbn, sum(num_stu),sum(num_class) FROM class_size WHERE grade='09-12' GROUP BY dbn")
colnames(class) <- c('dbn', 'total_stu', 'total_class')
class$avg_size = class$total_stu / class$total_class
#========== get gender ratio clean data ===========
gender <- read.csv("Graduation_Outcomes_School_Level_Classes_of_2005-2011_Gender.csv", header=T, stringsAsFactors = F)
gender = subset(gender, Cohort.Year==2007 & Cohort.Category=='4 Year August')
names(gender) <- tolower(names(gender))
gender <- select(gender, dbn, demographic, total.cohort.num)
female <- subset(gender, demographic=='Female')
male <- subset(gender, demographic=='Male')
female <- select(female, dbn, total.cohort.num)
male <- select(male, dbn, total.cohort.num)
names(female) = c('dbn', 'female')
names(male) = c('dbn', 'male')
gender <- merge(female, male, by = "dbn", all = TRUE)
gender[is.na(gender)] <- 0
gender$p_male = gender$male / (gender$male + gender$female)
#=========== get income data =============
income <- read.csv("zipcode_income.csv", header=T, stringsAsFactors = F)
colnames(income) = c('zip', 'zip_lonlat', 'zip_pop', 'avg_household')
income$avg_household = gsub('\\$','',income$avg_household)
income$avg_household = gsub(',','',income$avg_household)
income$avg_household = as.numeric(income$avg_household)
#=========== join tables ============
hsSAT <- inner_join(sat, hs, by="dbn")
all <- left_join(hsSAT, safety, by='dbn')
all <- left_join(all, class, by='dbn')
all <- left_join(all, gender, by='dbn')
all <- left_join(all, income, by='zip')
#=========== correlation models ============
normalize <- function(x) {
mean = mean(x[is.na(x)==FALSE])
sd = sd(x[is.na(x)==FALSE])
normalized_x = (x-mean)/sd
return(normalized_x)
}
all$critical_norm <- normalize(all$critical_avg)
all$math_norm <- normalize(all$math_avg)
all$writing_norm <- normalize(all$writing_avg)
all$avg_household_norm <- normalize(all$avg_household)
all$p_male_norm <- normalize(all$p_male)
all$avg_size_norm <- normalize(all$avg_size)
all$avgofmajor.n_norm <- normalize(all$avgofmajor.n)
all$avgofvio.n_norm <- normalize(all$avgofvio.n)
ggpairs(all, alpha=0.4)
